{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "The transformer is a neural network architecture that aims to capture long term dependencies in text data, it utilised the attention mechanism to better learn relationships between words in a sequence. It aimed to replace the already popular RNN architecure that was the main architecure for tasks like language modelling. Transformers have a large range of applications such as next word prediction, machine translation, image classification e.t.c. The purpose of this notebook is to be an introduction to the transformer architecture, we will understand what a transformer is and breakdown its working, then we will implement a simple decoder only transformer for the purpose of a task like next word prediction which we can use to generate text. The other files in this directory will then build on the basics being explained here for more specific tasks like implementing them on images, using transformers for machine translation etc.\n",
    "\n",
    "Reference Paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
