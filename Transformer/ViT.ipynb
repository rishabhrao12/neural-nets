{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT: Vision Transformers\n",
    "\n",
    "This notebook is demonstration and explanantion for a vision transformer. This architecture was created to use transformers which were created for language modelling, on images while at the same time changing as little of the transformer architecture as possible. The notebook will have an implementation of the vision transformer and will break down the purpose of each component in the architecture of the vision transformer. Finally it will be trained to perform a simple classification task on the large Food101 dataset.\n",
    "\n",
    "Reference Paper: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)\n",
    "\n",
    "Prerequisites: \n",
    "- Basic understanding of Neural Networks, Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
